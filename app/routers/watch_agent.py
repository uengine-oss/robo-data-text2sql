"""
Watch Agent - Text-to-SQL API
ìì—°ì–´ ê°ì‹œ ì¡°ê±´ì—ì„œ SQL ì¿¼ë¦¬ ìƒì„±

ê°ì‹œ ì—ì´ì „íŠ¸ì˜ ê´€ë¦¬ ê¸°ëŠ¥ì€ agent-scheduler ì„œë¹„ìŠ¤ì—ì„œ ë‹´ë‹¹í•©ë‹ˆë‹¤.
ì´ ë¼ìš°í„°ëŠ” Text-to-SQL ê¸°ëŠ¥ë§Œ ì œê³µí•©ë‹ˆë‹¤:
- ìì—°ì–´ì—ì„œ ë°ì´í„° ê°€ìš©ì„± ë¶„ì„
- ê°ì‹œìš© SQL ì¿¼ë¦¬ ìƒì„±
"""
import re
from typing import Any, Dict, List, Optional

from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel, Field

from app.deps import get_neo4j_session
from app.core.llm_factory import create_embedding_client
from app.core.graph_search import GraphSearcher, format_subschema_for_prompt
from app.core.prompt import SQLChain
from app.smart_logger import SmartLogger


router = APIRouter(prefix="/watch-agent", tags=["Watch Agent - Text-to-SQL"])


# =============================================================================
# Request/Response Models
# =============================================================================

class ChatMessage(BaseModel):
    """ì±„íŒ… ë©”ì‹œì§€"""
    role: str
    content: str


class ChatRequest(BaseModel):
    """ì—ì´ì „íŠ¸ ë¹Œë” ì±„íŒ… ìš”ì²­"""
    message: str = Field(..., description="ì‚¬ìš©ì ë©”ì‹œì§€")
    history: List[ChatMessage] = Field(default=[], description="ì´ì „ ëŒ€í™” ê¸°ë¡")
    current_config: Optional[Dict[str, Any]] = Field(default=None, description="í˜„ì¬ ì„¤ì • ìƒíƒœ")
    step: str = Field(default="initial", description="ì„¤ì • ë‹¨ê³„")


class ChatResponse(BaseModel):
    """ì—ì´ì „íŠ¸ ë¹Œë” ì±„íŒ… ì‘ë‹µ"""
    response: str
    extracted_config: Optional[Dict[str, Any]] = None
    generated_sql: Optional[str] = None
    ready_to_confirm: bool = False
    agent_created: bool = False
    data_available: bool = True
    relevant_tables: Optional[List[str]] = None


class SQLGenerationRequest(BaseModel):
    """SQL ìƒì„± ìš”ì²­"""
    question: str = Field(..., description="ìì—°ì–´ ì§ˆë¬¸")
    datasource: str = Field(..., description="MindsDB datasource (required; Phase 1 MindsDB-only)")


class SQLGenerationResponse(BaseModel):
    """SQL ìƒì„± ì‘ë‹µ"""
    sql: Optional[str] = None
    tables: List[str] = []
    available: bool = True
    message: str = ""


# =============================================================================
# Helper Functions
# =============================================================================

async def analyze_query_for_data_availability(
    question: str,
    datasource: str,
    neo4j_session,
) -> Dict[str, Any]:
    """ìì—°ì–´ ì¿¼ë¦¬ì—ì„œ ë°ì´í„° ê°€ìš©ì„± ë¶„ì„"""
    try:
        embedding_client = create_embedding_client()
        query_embedding = await embedding_client.embed_text(question)
        
        searcher = GraphSearcher(neo4j_session)
        ds = (datasource or "").strip()
        subschema = await searcher.build_subschema(query_embedding, datasource=(ds or None))
        
        if not subschema.tables:
            return {
                "available": False,
                "tables": [],
                "message": "ê´€ë ¨ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }
        
        table_names = [t.name for t in subschema.tables]
        return {
            "available": True,
            "tables": table_names,
            "subschema": subschema,
            "message": f"{len(table_names)}ê°œì˜ ê´€ë ¨ í…Œì´ë¸”ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤."
        }
    except Exception as e:
        return {
            "available": False,
            "tables": [],
            "message": f"ë°ì´í„° ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}"
        }


async def generate_monitoring_sql(
    question: str,
    subschema,
) -> str:
    """ê°ì‹œìš© SQL ì¿¼ë¦¬ ìƒì„±"""
    schema_text = format_subschema_for_prompt(subschema)
    join_hints = "\n".join(subschema.join_hints) if subschema.join_hints else ""
    
    sql_chain = SQLChain()
    
    # ê°ì‹œ íŠ¹í™” í”„ë¡¬í”„íŠ¸ ì¶”ê°€
    monitoring_hint = """
    ì´ ì¿¼ë¦¬ëŠ” ì£¼ê¸°ì  ëª¨ë‹ˆí„°ë§ì— ì‚¬ìš©ë©ë‹ˆë‹¤.
    - ìµœê·¼ ë°ì´í„°ë§Œ ì¡°íšŒí•˜ë„ë¡ ì‹œê°„ ì¡°ê±´ì„ í¬í•¨í•˜ì„¸ìš”
    - íŠ¸ë Œë“œ ë¶„ì„ì„ ìœ„í•´ LAG/LEAD ìœˆë„ìš° í•¨ìˆ˜ë¥¼ ê³ ë ¤í•˜ì„¸ìš”
    - ì§‘ê³„ í•¨ìˆ˜(AVG, MAX, MIN)ë¥¼ í™œìš©í•˜ì„¸ìš”
    """
    
    enhanced_question = f"{question}\n\n{monitoring_hint}"
    
    sql = await sql_chain.generate_sql(
        question=enhanced_question,
        schema_text=schema_text,
        join_hints=join_hints
    )
    
    return sql


def extract_config_from_message(message: str) -> Dict[str, Any]:
    """ë©”ì‹œì§€ì—ì„œ ì„¤ì • ì •ë³´ ì¶”ì¶œ"""
    config = {}
    
    # ì‹œê°„ ê°„ê²© ì¶”ì¶œ
    interval_match = re.search(r'(\d+)\s*(ë¶„|ì‹œê°„|ì´ˆ)', message)
    if interval_match:
        interval = int(interval_match.group(1))
        unit = interval_match.group(2)
        if unit == 'ì‹œê°„':
            interval *= 60
        elif unit == 'ì´ˆ':
            interval = max(1, interval // 60)
        config['check_interval_minutes'] = interval
    
    # í”„ë¡œì„¸ìŠ¤ ì´ë¦„ ì¶”ì¶œ
    process_match = re.search(r'(?:í”„ë¡œì„¸ìŠ¤|ì‹¤í–‰)[:\s]*([ê°€-í£\w_]+)', message, re.IGNORECASE)
    if process_match:
        config['process_name'] = process_match.group(1)
        config['process_id'] = process_match.group(1).lower().replace(' ', '_')
    
    # ì¡°ê±´ ì¶”ì¶œ
    if 'ì§€ì†' in message or 'ìƒìŠ¹' in message:
        config['condition_expression'] = 'trend == "rising"'
        config['condition_type'] = 'rising'
        config['condition_description'] = 'ì§€ì† ìƒìŠ¹'
    elif 'ì´ìƒ' in message or 'ì´ˆê³¼' in message:
        value_match = re.search(r'(\d+(?:\.\d+)?)\s*(ì´ìƒ|ì´ˆê³¼)', message)
        if value_match:
            config['condition_expression'] = f'value >= {value_match.group(1)}'
            config['condition_type'] = 'threshold'
            config['condition_description'] = f'{value_match.group(1)} ì´ìƒ'
    else:
        config['condition_type'] = 'exists'
        config['condition_expression'] = 'rows > 0'
        config['condition_description'] = 'ë°ì´í„° ì¡´ì¬'
    
    # ì´ë¦„ ì¶”ì¶œ
    name_patterns = [
        r'(ì›ìˆ˜|íƒë„|ìˆ˜ìœ„|ìœ ëŸ‰|ì˜¨ë„).{0,10}(ê°ì‹œ|ëª¨ë‹ˆí„°ë§)',
        r'(ê°ì‹œ|ëª¨ë‹ˆí„°ë§).{0,10}(ì—ì´ì „íŠ¸)'
    ]
    for pattern in name_patterns:
        name_match = re.search(pattern, message, re.IGNORECASE)
        if name_match:
            config['name'] = name_match.group(0)
            break
    
    if 'name' not in config:
        config['name'] = message[:30] + ('...' if len(message) > 30 else '')
    
    return config


# =============================================================================
# API Endpoints
# =============================================================================

@router.post("/chat", response_model=ChatResponse)
async def chat_with_builder(
    request: ChatRequest,
    neo4j_session=Depends(get_neo4j_session),
):
    """
    ì—ì´ì „íŠ¸ ë¹Œë”ì™€ ëŒ€í™”
    
    ìì—°ì–´ë¡œ ê°ì‹œ ì¡°ê±´ì„ ì„¤ëª…í•˜ë©´:
    1. Neo4jì—ì„œ ê´€ë ¨ ë°ì´í„° ê°€ìš©ì„± í™•ì¸
    2. SQL ì¿¼ë¦¬ ìƒì„±
    3. ì„¤ì • ì •ë³´ ì¶”ì¶œ
    
    ì‹¤ì œ ì—ì´ì „íŠ¸ ìƒì„±/ê´€ë¦¬ëŠ” agent-scheduler ì„œë¹„ìŠ¤ì—ì„œ ë‹´ë‹¹í•©ë‹ˆë‹¤.
    """
    SmartLogger.log(
        "INFO",
        "watch_agent.chat",
        category="watch_agent.chat",
        params={"message": request.message[:100], "step": request.step}
    )
    
    try:
        # ì„¤ì • ì •ë³´ ì¶”ì¶œ
        extracted_config = extract_config_from_message(request.message)
        if request.current_config:
            extracted_config = {**request.current_config, **extracted_config}
        
        # ìì—°ì–´ ì¿¼ë¦¬ ì €ì¥
        extracted_config['natural_language_query'] = request.message
        
        # ë°ì´í„° ê°€ìš©ì„± ë¶„ì„
        data_analysis = await analyze_query_for_data_availability(
            request.message,
            request.current_config.get("datasource") if isinstance(request.current_config, dict) else "",
            neo4j_session,
        )
        
        if not data_analysis["available"]:
            return ChatResponse(
                response=f"""ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

{data_analysis["message"]}

ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:
- ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆê°€ ë“±ë¡ë˜ì–´ ìˆëŠ”ì§€
- ê´€ë ¨ í…Œì´ë¸” ì´ë¦„ì´ ì˜¬ë°”ë¥¸ì§€

ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì‹œê² ì–´ìš”?""",
                data_available=False,
                relevant_tables=[]
            )
        
        # SQL ì¿¼ë¦¬ ìƒì„±
        generated_sql = await generate_monitoring_sql(
            request.message,
            data_analysis["subschema"],
        )
        
        extracted_config['generated_sql'] = generated_sql
        extracted_config['monitored_tables'] = data_analysis["tables"]
        
        # ì‘ë‹µ ìƒì„±
        interval = extracted_config.get('check_interval_minutes', 10)
        process_name = extracted_config.get('process_name', '(ì§€ì • í•„ìš”)')
        condition = extracted_config.get('condition_description', 'ë°ì´í„° ì¡´ì¬')
        
        response_text = f"""ì´í•´í–ˆìŠµë‹ˆë‹¤! ê°ì‹œ ì—ì´ì „íŠ¸ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±í•˜ê² ìŠµë‹ˆë‹¤.

ğŸ” **ê°ì‹œ ëŒ€ìƒ**
{request.message}

ğŸ“Š **ê´€ë ¨ í…Œì´ë¸”**: {', '.join(data_analysis["tables"][:5])}

â±ï¸ **ê°ì‹œ ì£¼ê¸°**: {interval}ë¶„ë§ˆë‹¤ í™•ì¸

ğŸ“‹ **ì¡°ì¹˜ ì¡°ê±´**: {condition}

âš¡ **ì¡°ì¹˜**: ProcessGPT í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
â”” í”„ë¡œì„¸ìŠ¤: {process_name}

ì•„ë˜ SQL ì¿¼ë¦¬ë¡œ ë°ì´í„°ë¥¼ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤. ìˆ˜ì •ì´ í•„ìš”í•˜ë©´ ë§ì”€í•´ì£¼ì„¸ìš”."""

        return ChatResponse(
            response=response_text,
            extracted_config=extracted_config,
            generated_sql=generated_sql,
            ready_to_confirm=True,
            data_available=True,
            relevant_tables=data_analysis["tables"]
        )
        
    except Exception as e:
        SmartLogger.log(
            "ERROR",
            "watch_agent.chat.error",
            category="watch_agent.chat.error",
            params={"error": str(e)}
        )
        return ChatResponse(
            response=f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\në‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            data_available=False
        )


@router.post("/generate-sql", response_model=SQLGenerationResponse)
async def generate_sql(
    request: SQLGenerationRequest,
    neo4j_session=Depends(get_neo4j_session),
):
    """
    ìì—°ì–´ì—ì„œ ê°ì‹œìš© SQL ì¿¼ë¦¬ ìƒì„±
    
    í”„ë¡ íŠ¸ì—”ë“œì—ì„œ SQL ìƒì„±ë§Œ í•„ìš”í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    try:
        # ë°ì´í„° ê°€ìš©ì„± ë¶„ì„
        data_analysis = await analyze_query_for_data_availability(
            request.question,
            request.datasource,
            neo4j_session,
        )
        
        if not data_analysis["available"]:
            return SQLGenerationResponse(
                sql=None,
                tables=[],
                available=False,
                message=data_analysis["message"]
            )
        
        # SQL ìƒì„±
        sql = await generate_monitoring_sql(
            request.question,
            data_analysis["subschema"],
        )
        
        return SQLGenerationResponse(
            sql=sql,
            tables=data_analysis["tables"],
            available=True,
            message=f"{len(data_analysis['tables'])}ê°œ í…Œì´ë¸”ì—ì„œ SQLì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤."
        )
        
    except Exception as e:
        return SQLGenerationResponse(
            sql=None,
            tables=[],
            available=False,
            message=f"SQL ìƒì„± ì˜¤ë¥˜: {str(e)}"
        )


@router.post("/analyze-availability")
async def analyze_availability(
    request: SQLGenerationRequest,
    neo4j_session=Depends(get_neo4j_session),
):
    """
    ìì—°ì–´ ì¿¼ë¦¬ì˜ ë°ì´í„° ê°€ìš©ì„± ë¶„ì„
    
    SQL ìƒì„± ì „ì— ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ”ì§€ ë¨¼ì € í™•ì¸í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    data_analysis = await analyze_query_for_data_availability(
        request.question,
        request.datasource,
        neo4j_session,
    )
    
    return {
        "available": data_analysis["available"],
        "tables": data_analysis.get("tables", []),
        "message": data_analysis["message"]
    }
